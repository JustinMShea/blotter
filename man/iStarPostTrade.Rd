% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/iStar.R
\name{iStarPostTrade}
\alias{iStarPostTrade}
\title{The Kissell-Malamut \emph{I-Star} Market Impact model}
\usage{
iStarPostTrade(
  MktData,
  sessions = NULL,
  yrBizdays = 250,
  horizon = 30,
  xtsfy = FALSE,
  grouping = FALSE,
  groupsBounds,
  minGroupDps,
  paramsBounds,
  paramsInit,
  OrdData = NULL,
  ...
)
}
\arguments{
\item{MktData}{A list of \code{xts} objects, each representing a security market data. See 'Details'}

\item{sessions}{A character or a vector of character representing ISO time subsets to split each trading day in "sessions". If not specified, sessions will be assumed to be on a daily basis}

\item{yrBizdays}{A numeric value, the number of business days in a given year data refers to. Default is 250 days}

\item{horizon}{A numeric value, the number of sessions to compute the rolling variables over. Default is 30. See 'Details'}

\item{xtsfy}{A boolean specifying whether the rolling variables computed should become \code{xts} object with consistent dates}

\item{grouping}{A boolean or vector of booleans to specifying whether to group datapoints. Eventually, the second element specifies whether to average group values. Attention: the grouping may discard data. See 'Details'}

\item{groupsBounds}{A vector with named elements being 'ImSize', 'POV', 'Vol'. They have to be increasing sequences expressing the respective variable bounds, which are used to build datapoints groups. See 'Details'}

\item{minGroupDps}{A numeric value, the minimum number of datapoints a group should have to be included in the estimation process. Default is 25. See 'Details'}

\item{paramsBounds}{A matrix providing model parameters bounds to pass to \code{nls}. Parameters are considered by row and columns represents lower and upper bounds, respectively. See 'Details'}

\item{paramsInit}{A list providing model paramaters initial values to pass to \code{nls}. Elements should be named with the corresponding parameter, i.e. 'a_1', 'a_2', 'a_3', 'a_4' and 'b_1'. See 'Details'}

\item{OrdData}{A \code{data.frame} providing custom order data specifics to estimate the impacts for, with required columns 'Side', 'Size', 'ArrPrice', 'AvgExecPrice', 'POV' and 'AnnualVol'. Or a \code{list} consisting of 'Order.Data' and 'Params' items. See 'Details'}

\item{...}{Any other passthrough parameter}
}
\value{

}
\description{
The model is a cost allocation method to quantify the market impact of financial
transactions, depending on an agent order size relative to the market volume;  
in the authors words is theoretically based on the supply-demand principle, 
although it may be rather difficult to express ourselves precisely in these 
terms and even so our interpretations may differ by the several possible 
scenarios that take place into the market in response to imbalances.
}
\details{
Theoretically the I-Star model can be estimated using private order data for
which one intends to estimate the impact costs. The main limitations of this 
approach are: on one hand the lack of data and the effect of neglecting the 
effect of wider market movements than the ones of the single security on which 
the order was placed, on the other it may include potential opportunistic trading 
biases. Based on these considerations we follow Kissell's main discussion line, 
focusing on the use of market "tic data" and derived quantities that represent 
proxies of the corresponding order-related variables.


The \code{MktData} input dataset must be a list, with items being market data
by security considered. These items must be named to match the security they refer to.
Each item is required to be an \code{xts} object having at least 'MktPrice' and 
'MktQty' columns. For theoretical accuracy of the arrival price it is recommended 
to input 'Bid' and 'Ask' columns as well. Similarly, providing a 'Reason' column 
allows to have trades classified by your preferred criterion; when this data is 
not available the \emph{Lee-Ready tick test} will be used to infer the trade direction.
If the \code{MktData} list provided has items with different number of observations,
then data considered will be only until to match the item with the smallest number
of observations. Also, beware that to avoid strict restrictions on potentially
mismatching intraday timestamps there is no timestamps complete matching, therefore:
provide a dataset with securities included observed on the same number of unique
days, consistently across the full dataset.
Our best suggestion is to use a data set within the same timeframe and including 
the same number of days for each security involved in the analysis.

The \code{horizon} should be chosen according to the number of \code{sessions}
a trading day is splitted into.

Parameters \code{groupsBounds} and \code{minGroupDps} regulate the grouping process.
\code{minGroupDps} of each group has to be reached in order to let its datapoints 
be included in the estimation process. It dafaults to 25 datapoints, as suggested 
by the author. However, this appears to be a rule of thumb, as the parameter largerly 
depends on the given original dataset and on others parameters such as the \code{sessions} 
and \code{horizon} specifications.
\code{groupsBounds} defaults to the following sequences: 
\tabular{rl}{
  Imbalance Size        \tab 0.005, 0.01, 0.02, ..., 0.3 \cr
  Annualized volatility \tab 0.1, 0.2, ..., 0.8          \cr
  POV                   \tab 0.01, 0.05, 0.1, ..., 0.65  \cr
}
Where each interval is considered to be left opened and right closed.
Again, these values are suggested by the author and appear to come from empirical 
findings.

For the estimation we use \code{nls}, specifying the \code{algorithm = 'port'} 
in order to implement the constrained problem the author proposes.
Parameters starting values are provided with \code{paramsInit}, if missing they 
are chosen to be their respective lower bound. Note that specified values must 
be included in the corresponding \code{paramsBounds}.
If missing, default values for the bounds are:
\tabular{c}{
 100 <= a_1 <= 1000 \cr
 0.1 <= a_2 <= 1    \cr
 0.1 <= a_3 <= 1    \cr
 0.1 <= a_4 <= 1    \cr
 0.7 <= b_1 <= 1    \cr
}
Note that by definition \eqn{0 <= b_1 <= 1}, however the author reports using 
\eqn{0.7} as an empirical value. Nonetheless, the user if left free to specify desired 
parameters bounds via \code{paramBounds}, where the rows must follow a_1, a_2, 
a_3, a_4 and b_1 order or be named accordingly. 


\code{OrdData} can be a \code{data.frame} or \code{list}. When it is a \code{data.frame},
\code{OrdData} columns are required to be: 'Side', a numeric value being 1 ("buy")
or -1 ("sell"); 'Size', the order size expressed in terms of , that is the ratio 
between the total number of traded units and that the ADV on the day the order 
was traded ; 'ArrPrice', a numeric value expressing the price of the traded 
security (for theoretical accuracy it is recommended to use the corresponding 
bid-ask spreads midpoint); 'AvgExecPrice', specifying the average execution 
price over the order lifetime; the 'POV' of and the 'AnnualVol', the order 
percentage of volume and annualized volatility respectively. 
Whereas, when \code{OrdData} is a \code{list} it has to contain two named elements:
'Order.Data', a \code{data.frame} with the same characteristics as above and 
'Params', a vector consisting of named elements being the paramaters to use in 
the I-Star equations to compute the impact costs and the error measures.
This is useful in cases one already has estimated parameters for the model or 
simply wants to see what I-Star model values would look like with different 
paramaters, perhaps those coming from the sensitivity analysis carried with 
\code{iStarSensitivity}.   

TODO: stock specific analysis is a WIP (it shouldn't be hard to integrate in 
function flow already in place, see it in light of further analyses such as 
error analysis. Also for testing purposes other kind of data such as market 
capitalization is needed)
}
\references{
\emph{The Science of Algorithmic Trading and Portfolio Management} (Kissell, 2013), Elsevier Science.
\emph{A Practical Framework for Estimating Transaction Costs and Developing Optimal Trading Strategies to Achieve Best Execution} (Kissell, Glantz and Malamut, 2004), Finance Research Letters.
\emph{Inferring Trade Direction from Intraday Data} (Lee and Ready, 1991), The Journal of Finance.
\emph{Modern Applied Statistics with S} (Venables and Ripley, 2002), Springer.
}
\seealso{
\code{\link[PerformanceAnalytics]{Return.calculate}},
   \code{\link[PerformanceAnalytics]{sd.annualized}},
   \code{\link[stats]{nls}}
}
\author{
Vito Lestingi
}
